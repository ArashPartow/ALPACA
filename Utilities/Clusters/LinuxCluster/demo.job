#!/bin/sh

# Initial working directory:
#SBATCH -D <InitialDir>

# Job name
#SBATCH -J <JobName>

# Output and error files
#SBATCH -o %j-%x.out
#SBATCH -e %j-%x.err

# Notification
#SBATCH --mail-type=end
#SBATCH --mail-user=<your-email>@<your-host.domain>

# Where to run the simulation
#SBATCH --clusters=<cluster>
#SBATCH --partition=<partition>
#SBATCH --qos=<QOS>

# Request ressources
#SBATCH --nodes=<#Nodes>
#SBATCH --tasks-per-node=28
#SBATCH --time=<HH:MM:SS>

# Setup execution environment
#SBATCH --export=NONE
#SBATCH --get-user-env
module load slurm_setup

module unload intel-mpi
module unload intel-mkl
module unload intel

module load intel-mpi/2019-gcc
module load hdf5/1.10.6-gcc8-impi

## Commenting in the following line may help with stalling I/O
## export I_MPI_EXTRA_FILESYSTEM=on

## In case of RAM shortage try using mpiexec's -rr option (not supported by all MPI Libraries)
mpiexec ./ALPACA ./<your-inputfile>.xml
